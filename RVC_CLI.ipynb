{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pKllbPyK_BC"
      },
      "source": [
        "# RVC_CLI\n",
        "Created by [Blaise](https://github.com/blaise-tk) and based on [RVC_CLI](https://github.com/blaise-tk/RVC_CLI).\n",
        "\n",
        "- Colab inspired on [RVC v2 Disconnected](https://colab.research.google.com/drive/1XIPCP9ken63S7M6b5ui1b36Cs17sP-NS).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymMCTSD6m8qV"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yFhAeKGOp9aa"
      },
      "outputs": [],
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7GysECSxBya4"
      },
      "outputs": [],
      "source": [
        "#@title Clone\n",
        "!git clone https://github.com/blaise-tk/RVC_CLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CAXW55BQm0PP"
      },
      "outputs": [],
      "source": [
        "#@title Install\n",
        "%cd RVC_CLI\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QlTibPnjmj6-"
      },
      "outputs": [],
      "source": [
        "#@title Download models\n",
        "!python rvc/lib/tools/prerequisites_download.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzaeMYsUE97Y"
      },
      "source": [
        "# Infer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "v0EgikgjFCjE"
      },
      "outputs": [],
      "source": [
        "#@title Download model\n",
        "#@markdown Hugging Face or Google Drive\n",
        "model_link = \"https://drive.google.com/file/d/1rneJ3O2IIQm151-Hci-ZKQxPhg0Xdm4o\" #@param {type:\"string\"}\n",
        "\n",
        "!python main.py download {model_link}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lrCKEOzvDPRu"
      },
      "outputs": [],
      "source": [
        "#@title Run Inference\n",
        "#@markdown Please upload the audio file to your Google Drive path `/content/drive/MyDrive` and specify its name here. For the model name, use the zip file name without the extension. Alternatively, you can check the path `/content/RVC_CLI/models` for the model name (name of the folder).\n",
        "\n",
        "import os\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "model_name = \"Darwin\" #@param {type:\"string\"}\n",
        "model_folder = os.path.join(current_dir, f\"logs/models/{model_name}\")\n",
        "\n",
        "if not os.path.exists(model_folder):\n",
        "    raise FileNotFoundError(f\"Model directory not found: {model_folder}\")\n",
        "\n",
        "files_in_folder = os.listdir(model_folder)\n",
        "pth_file = next((f for f in files_in_folder if f.endswith('.pth')), None)\n",
        "index_file = next((f for f in files_in_folder if f.endswith('.index')), None)\n",
        "\n",
        "if pth_file is None or index_file is None:\n",
        "    raise FileNotFoundError(\"No model found.\")\n",
        "\n",
        "pth_file = os.path.join(model_folder, pth_file)\n",
        "index_file = os.path.join(model_folder, index_file)\n",
        "\n",
        "input_path = \"/content/drive/MyDrive/vocals.wav\" #@param {type:\"string\"}\n",
        "output_path = \"/content/output.wav\"\n",
        "f0method = \"rmvpe\" #@param [\"pm\", \"dio\", \"crepe\", \"crepe-tiny\", \"harvest\", \"rmvpe\"] {allow-input: false}\n",
        "f0up_key = 0 #@param {type:\"slider\", min:-24, max:24, step:0}\n",
        "filter_radius = 0 #@param {type:\"slider\", min:0, max:10, step:0}\n",
        "index_rate = 0.0 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "hop_length = 1 # @param {type:\"slider\", min:1, max:512, step:0}\n",
        "split_audio = False #@param{type:\"boolean\"}\n",
        "!python main.py infer {f0up_key} {filter_radius} {index_rate} {hop_length} {f0method} \"{input_path}\" \"{output_path}\" \"{pth_file}\" \"{index_file}\" {split_audio}\n",
        "\n",
        "from IPython.display import Audio, display, clear_output\n",
        "clear_output()\n",
        "display(Audio(output_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QkabnLlF2KB"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oBzqm4JkGGa0"
      },
      "outputs": [],
      "source": [
        "#@title Preprocess Dataset\n",
        "model_name = \"Darwin\" #@param {type:\"string\"}\n",
        "dataset_path = \"/content/drive/MyDrive/Darwin_Dataset\" #@param {type:\"string\"}\n",
        "\n",
        "sample_rate = \"40k\" #@param [\"32k\", \"40k\", \"48k\"] {allow-input: false}\n",
        "sr = int(sample_rate.rstrip('k'))*1000\n",
        "\n",
        "!python main.py preprocess \"{model_name}\" \"{dataset_path}\" {sr}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zWMiMYfRJTJv"
      },
      "outputs": [],
      "source": [
        "#@title Extract Features\n",
        "model_name = \"Darwin\" #@param {type:\"string\"}\n",
        "rvc_version = \"v2\" #@param [\"v2\", \"v1\"] {allow-input: false}\n",
        "f0method = \"rmvpe\" #@param [\"pm\", \"dio\", \"crepe\", \"crepe-tiny\", \"harvest\", \"rmvpe\"] {allow-input: false}\n",
        "hop_length = 128 #@param {type:\"slider\", min:1, max:512, step:0}\n",
        "sample_rate = \"40k\" #@param [\"32k\", \"40k\", \"48k\"] {allow-input: false}\n",
        "sr = int(sample_rate.rstrip('k'))*1000\n",
        "\n",
        "!python main.py extract {model_name} {rvc_version} {f0method} {hop_length} {sr}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TI6LLdIzKAIa"
      },
      "outputs": [],
      "source": [
        "#@title Train\n",
        "import requests\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import hashlib\n",
        "import time\n",
        "\n",
        "LOGS_FOLDER = '/content/RVC_CLI/logs/'\n",
        "WEIGHTS_FOLDER = LOGS_FOLDER + model_name\n",
        "GOOGLE_DRIVE_PATH = '/content/drive/MyDrive/RVC_Backup'\n",
        "\n",
        "def import_google_drive_backup():\n",
        "    print(\"Importing Google Drive backup...\")\n",
        "    weights_exist = False\n",
        "    for root, dirs, files in os.walk(GOOGLE_DRIVE_PATH):\n",
        "        for filename in files:\n",
        "            filepath = os.path.join(root, filename)\n",
        "            if os.path.isfile(filepath) and not filepath.startswith(os.path.join(GOOGLE_DRIVE_PATH, 'weights')):\n",
        "                backup_filepath = os.path.join(LOGS_FOLDER, os.path.relpath(filepath, GOOGLE_DRIVE_PATH))\n",
        "                backup_folderpath = os.path.dirname(backup_filepath)\n",
        "                if not os.path.exists(backup_folderpath):\n",
        "                    os.makedirs(backup_folderpath)\n",
        "                    print(f'Created backup folder: {backup_folderpath}', flush=True)\n",
        "                shutil.copy2(filepath, backup_filepath) # copy file with metadata\n",
        "                print(f'Imported file from Google Drive backup: {filename}')\n",
        "            elif filepath.startswith(os.path.join(GOOGLE_DRIVE_PATH, 'weights')) and filename.endswith('.pth'):\n",
        "                weights_exist = True\n",
        "                weights_filepath = os.path.join(WEIGHTS_FOLDER, os.path.relpath(filepath, os.path.join(GOOGLE_DRIVE_PATH, 'weights')))\n",
        "                weights_folderpath = os.path.dirname(weights_filepath)\n",
        "                if not os.path.exists(weights_folderpath):\n",
        "                    os.makedirs(weights_folderpath)\n",
        "                    print(f'Created weights folder: {weights_folderpath}', flush=True)\n",
        "                shutil.copy2(filepath, weights_filepath) # copy file with metadata\n",
        "                print(f'Imported file from weights: {filename}')\n",
        "    if weights_exist:\n",
        "        print(\"Copied weights from Google Drive backup to local weights folder.\")\n",
        "    else:\n",
        "        print(\"No weights found in Google Drive backup.\")\n",
        "    print(\"Google Drive backup import completed.\")\n",
        "\n",
        "def get_md5_hash(file_path):\n",
        "    hash_md5 = hashlib.md5()\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
        "            hash_md5.update(chunk)\n",
        "    return hash_md5.hexdigest()\n",
        "\n",
        "def copy_weights_folder_to_drive():\n",
        "    destination_folder = os.path.join(GOOGLE_DRIVE_PATH, 'weights')\n",
        "    try:\n",
        "        if not os.path.exists(destination_folder):\n",
        "            os.makedirs(destination_folder)\n",
        "\n",
        "        num_copied = 0\n",
        "        for filename in os.listdir(WEIGHTS_FOLDER):\n",
        "            if filename.endswith('.pth'):\n",
        "                source_file = os.path.join(WEIGHTS_FOLDER, filename)\n",
        "                destination_file = os.path.join(destination_folder, filename)\n",
        "                if not os.path.exists(destination_file):\n",
        "                    shutil.copy2(source_file, destination_file)\n",
        "                    num_copied += 1\n",
        "                    print(f\"Copied {filename} to Google Drive!\")\n",
        "\n",
        "        if num_copied == 0:\n",
        "            print(\"No new finished models found for copying.\")\n",
        "        else:\n",
        "            print(f\"Finished copying {num_copied} files to Google Drive!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while copying weights: {str(e)}\")\n",
        "\n",
        "def backup_files():\n",
        "    print(\"\\nStarting backup loop...\")\n",
        "    last_backup_timestamps_path = os.path.join(LOGS_FOLDER, 'last_backup_timestamps.txt')\n",
        "    fully_updated = False\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            updated = False\n",
        "            last_backup_timestamps = {}\n",
        "\n",
        "            try:\n",
        "                with open(last_backup_timestamps_path, 'r') as f:\n",
        "                    last_backup_timestamps = dict(line.strip().split(':') for line in f)\n",
        "            except FileNotFoundError:\n",
        "                pass\n",
        "\n",
        "            for root, files in os.walk(LOGS_FOLDER):\n",
        "                for filename in files:\n",
        "                    if filename != 'last_backup_timestamps.txt':\n",
        "                        filepath = os.path.join(root, filename)\n",
        "                        if os.path.isfile(filepath):\n",
        "                            backup_filepath = os.path.join(GOOGLE_DRIVE_PATH, os.path.relpath(filepath, LOGS_FOLDER))\n",
        "                            backup_folderpath = os.path.dirname(backup_filepath)\n",
        "                            if not os.path.exists(backup_folderpath):\n",
        "                                os.makedirs(backup_folderpath)\n",
        "                                print(f'Created backup folder: {backup_folderpath}', flush=True)\n",
        "                            last_backup_timestamp = last_backup_timestamps.get(filepath)\n",
        "                            current_timestamp = os.path.getmtime(filepath)\n",
        "                            if last_backup_timestamp is None or float(last_backup_timestamp) < current_timestamp:\n",
        "                                shutil.copy2(filepath, backup_filepath)  \n",
        "                                last_backup_timestamps[filepath] = str(current_timestamp) \n",
        "                                if last_backup_timestamp is None:\n",
        "                                    print(f'Backed up file: {filename}')\n",
        "                                else:\n",
        "                                    print(f'Updating backed up file: {filename}')\n",
        "                                updated = True\n",
        "                                fully_updated = False  \n",
        "\n",
        "            for filepath in list(last_backup_timestamps.keys()):\n",
        "                if not os.path.exists(filepath):\n",
        "                    backup_filepath = os.path.join(GOOGLE_DRIVE_PATH, os.path.relpath(filepath, LOGS_FOLDER))\n",
        "                    if os.path.exists(backup_filepath):\n",
        "                        os.remove(backup_filepath)\n",
        "                        print(f'Deleted file: {filepath}')\n",
        "                    del last_backup_timestamps[filepath]\n",
        "                    updated = True\n",
        "                    fully_updated = False  \n",
        "\n",
        "            if not updated and not fully_updated:\n",
        "                print(\"Files are up to date.\")\n",
        "                fully_updated = True  \n",
        "                copy_weights_folder_to_drive()\n",
        "                sleep_time = 15\n",
        "            else:\n",
        "                sleep_time = 0.1\n",
        "\n",
        "            with open(last_backup_timestamps_path, 'w') as f:\n",
        "                for filepath, timestamp in last_backup_timestamps.items():\n",
        "                    f.write(f'{filepath}:{timestamp}\\n')\n",
        "\n",
        "            time.sleep(sleep_time)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "model_name = \"Darwin\" #@param {type:\"string\"}\n",
        "rvc_version = \"v2\" #@param [\"v2\", \"v1\"] {allow-input: false}\n",
        "save_every_epoch = 10 #@param {type:\"slider\", min:1, max:100, step:0}\n",
        "save_only_latest = False #@param{type:\"boolean\"}\n",
        "save_every_weights = False #@param{type:\"boolean\"}\n",
        "total_epoch = 800 #@param {type:\"slider\", min:1, max:10000, step:0}\n",
        "sample_rate = \"40k\" #@param [\"32k\", \"40k\", \"48k\"] {allow-input: false}\n",
        "batch_size = 15 #@param {type:\"slider\", min:1, max:25, step:0}\n",
        "gpu = 0 # @param {type:\"number\"}\n",
        "sr = int(sample_rate.rstrip('k'))*1000\n",
        "pitch_guidance = True #@param{type:\"boolean\"}\n",
        "pretrained = True #@param{type:\"boolean\"}\n",
        "custom_pretrained = False #@param{type:\"boolean\"}\n",
        "g_pretrained_path = 'Custom Path' # @param {type:\"string\"}\n",
        "d_pretrained_path = 'Custom Path' # @param {type:\"string\"}\n",
        "auto_backups = True #@param{type:\"boolean\"}\n",
        "def start_train():\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir /content/RVC_CLI/logs/\n",
        "  !python main.py train {model_name} {rvc_version} {save_every_epoch} {save_only_latest} {save_every_weights} {total_epoch} {sr} {batch_size} {gpu} {pitch_guidance} {pretrained} {custom_pretrained} {g_pretrained_path} {d_pretrained_path}\n",
        "\n",
        "server_thread = threading.Thread(target=start_train)\n",
        "server_thread.start()\n",
        "\n",
        "if auto_backups:\n",
        "    backup_files()\n",
        "else:\n",
        "    while True:\n",
        "        time.sleep(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bHLs5AT4Q1ck"
      },
      "outputs": [],
      "source": [
        "#@title Generate index file\n",
        "model_name = \"Darwin\" #@param {type:\"string\"}\n",
        "rvc_version = \"v2\" #@param [\"v2\", \"v1\"] {allow-input: false}\n",
        "\n",
        "!python main.py index {model_name} {rvc_version}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "X_eU_SoiHIQg"
      },
      "outputs": [],
      "source": [
        "#@title Save model\n",
        "#@markdown Enter the name of the model and the steps. You can find it in your `/content/RVC_CLI/logs` folder.\n",
        "%cd /content\n",
        "import shutil, os\n",
        "model_name = \"Darwin\"  #@param {type:\"string\"}\n",
        "model_epoch = 800  #@param {type:\"integer\"}\n",
        "save_big_file = False #@param {type:\"boolean\"}\n",
        "\n",
        "if os.path.exists('/content/zips'):\n",
        "  shutil.rmtree('/content/zips')\n",
        "print('Removed zips.')\n",
        "!mkdir -p /content/zips/{model_name}/\n",
        "print('Created zips.')\n",
        "if f\"{model_name}.pth\" not in os.listdir(f'/content/RVC_CLI/weights'):\n",
        "  print('There is no weight file with that name')\n",
        "if not save_big_file:\n",
        "  !cp /content/RVC_CLI/logs/{model_name}/added_*.index /content/zips/{model_name}/\n",
        "  !cp /content/RVC_CLI/logs/{model_name}/total_*.npy /content/zips/{model_name}/\n",
        "  !cp /content/RVC_CLI/weights/{model_name}.pth /content/zips/{model_name}/{model_name}{model_epoch}.pth\n",
        "  %cd /content/zips\n",
        "  !zip -r {model_name}.zip {model_name}\n",
        "if save_big_file:\n",
        "  %cd /content/RVC_CLI\n",
        "  latest_steps = -1\n",
        "  logs_folder = './logs/' + model_name\n",
        "  for filename in os.listdir(logs_folder):\n",
        "    if filename.startswith('G_') and filename.endswith('.pth'):\n",
        "      steps = int(filename.split('_')[1].split('.')[0])\n",
        "      if steps > latest_steps:\n",
        "        latest_steps = steps\n",
        "  MODELZIP = model_name + '.zip'\n",
        "  !mkdir -p /content/zips\n",
        "  ZIPFILEPATH = os.path.join('/content/zips', MODELZIP)\n",
        "  for filename in os.listdir(logs_folder):\n",
        "    if 'G_' in filename or 'D_' in filename:\n",
        "      if str(latest_steps) in filename:\n",
        "        !zip -r {ZIPFILEPATH} {os.path.join(logs_folder, filename)}\n",
        "    else:\n",
        "      !zip -r {ZIPFILEPATH} {os.path.join(logs_folder, filename)}\n",
        "  for filename in os.listdir('./weights'):\n",
        "    if MODELNAME in filename:\n",
        "      !zip -r {ZIPFILEPATH} {os.path.join('./weights/', filename)}\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/RVC_Backup/\n",
        "shutil.move(f'/content/zips/{model_name}.zip',f'/content/drive/MyDrive/RVC_Backup/{model_name}.zip')\n",
        "%cd /content\n",
        "shutil.rmtree(\"/content/zips\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ymMCTSD6m8qV"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
